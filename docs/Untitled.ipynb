{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21a7a0e-0477-42a6-8f58-1317d4f41be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install PyPDF2 --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea67eec2-e93c-4bcb-82e0-b34aa1332770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\Users\\niamh\\docs\n",
      "PDFs found: []\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "print(\"PDFs found:\", [os.path.basename(p) for p in glob.glob(\"docs/*.pdf\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96876e4-bfd1-46fb-b4db-b341b07e00c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Create a 'docs/' folder first and put your PDFs there.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m Create a 'docs/' folder first and put your PDFs there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niamh\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import re, json, math, textwrap\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict\n",
    "import PyPDF2\n",
    "\n",
    "DOCS_DIR = Path(\"docs\")\n",
    "MEMORY_FILE = Path(\"memory.json\")\n",
    "\n",
    "# ---------- PDF loading ----------\n",
    "def extract_text_from_pdf(path: Path) -> str:\n",
    "    text = []\n",
    "    with open(path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            t = page.extract_text() or \"\"\n",
    "            text.append(t)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def chunk_text(text: str, max_chars=1200):\n",
    "    # sentence-ish split, then recombine to ~max_chars chunks\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+|\\n{2,}\", text)\n",
    "    chunks, cur = [], \"\"\n",
    "    for s in sentences:\n",
    "        s = s.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if len(cur) + len(s) + 1 <= max_chars:\n",
    "            cur += (\" \" if cur else \"\") + s\n",
    "        else:\n",
    "            if cur: chunks.append(cur.strip())\n",
    "            cur = s\n",
    "    if cur: chunks.append(cur.strip())\n",
    "    return chunks\n",
    "\n",
    "def load_pdf_corpus() -> List[Dict]:\n",
    "    docs = []\n",
    "    for p in DOCS_DIR.glob(\"**/*.pdf\"):\n",
    "        try:\n",
    "            raw = extract_text_from_pdf(p)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: couldn't read {p.name}: {e}\")\n",
    "            continue\n",
    "        for i, ch in enumerate(chunk_text(raw)):\n",
    "            docs.append({\"path\": str(p), \"chunk_id\": i, \"text\": ch})\n",
    "    return docs\n",
    "\n",
    "# ---------- tiny text utils ----------\n",
    "def clean(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def tokenize(text: str):\n",
    "    return [t for t in clean(text).split() if t]\n",
    "\n",
    "# ---------- retrieval (simple TF-IDF-ish + cosine) ----------\n",
    "def build_idf(chunks):\n",
    "    df = Counter()\n",
    "    seen = defaultdict(set)\n",
    "    for idx, ch in enumerate(chunks):\n",
    "        for w in set(tokenize(ch[\"text\"])):\n",
    "            seen[w].add(idx)\n",
    "    N = len(chunks)\n",
    "    idf = {w: math.log((N + 1) / (1 + len(idxs))) + 1 for w, idxs in seen.items()}\n",
    "    return idf\n",
    "\n",
    "def score_chunk(query_tokens, chunk_text, idf):\n",
    "    words = tokenize(chunk_text)\n",
    "    tf = Counter(words)\n",
    "    num = 0.0; q_sum = 0.0; d_sum = 0.0\n",
    "    vocab = set(query_tokens) | set(words)\n",
    "    for w in vocab:\n",
    "        qw = (1.0 if w in query_tokens else 0.0) * idf.get(w, 1.0)\n",
    "        dw = tf[w] * idf.get(w, 1.0)\n",
    "        num += qw * dw\n",
    "        q_sum += qw * qw\n",
    "        d_sum += dw * dw\n",
    "    denom = (math.sqrt(q_sum) * math.sqrt(d_sum)) or 1e-9\n",
    "    return num / denom\n",
    "\n",
    "def retrieve(query, chunks, idf, k=3):\n",
    "    q_tokens = tokenize(query)\n",
    "    scored = [(score_chunk(q_tokens, ch[\"text\"], idf), ch) for ch in chunks]\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "    return [ch for score, ch in scored[:k] if score > 0]\n",
    "\n",
    "# ---------- tiny summarizer ----------\n",
    "def summarize(query, passages):\n",
    "    q_set = set(tokenize(query))\n",
    "    candidates = []\n",
    "    for p in passages:\n",
    "        # split to sentences; keep ones overlapping query terms\n",
    "        for s in re.split(r\"(?<=[.!?])\\s+\", p[\"text\"]):\n",
    "            toks = set(tokenize(s))\n",
    "            overlap = len(q_set & toks)\n",
    "            if overlap:\n",
    "                candidates.append((overlap, s.strip(), p[\"path\"]))\n",
    "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
    "    if not candidates:\n",
    "        return \"I couldn't find anything relevant in your PDFs.\", []\n",
    "    picks = candidates[:4]\n",
    "    body = \" \".join(s for _, s, _ in picks)\n",
    "    body = textwrap.shorten(body, width=800, placeholder=\" ...\")\n",
    "    sources = sorted({src for _, _, src in picks})\n",
    "    return body, sources\n",
    "\n",
    "# ---------- memory ----------\n",
    "def append_memory(query, answer, sources):\n",
    "    entry = {\"query\": query, \"answer\": answer, \"sources\": sources}\n",
    "    try:\n",
    "        data = json.loads(MEMORY_FILE.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        data = []\n",
    "    data.append(entry)\n",
    "    MEMORY_FILE.write_text(json.dumps(data, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# ---------- index at module load ----------\n",
    "if not DOCS_DIR.exists():\n",
    "    raise SystemExit(\"Create a 'docs/' folder first and put your PDFs there.\")\n",
    "\n",
    "pdf_chunks = load_pdf_corpus()\n",
    "if not pdf_chunks:\n",
    "    print(\"No PDFs found in docs/. Add files and re-run this cell.\")\n",
    "else:\n",
    "    idf = build_idf(pdf_chunks)\n",
    "    print(f\"Indexed {len({c['path'] for c in pdf_chunks})} PDFs, {len(pdf_chunks)} chunks.\")\n",
    "\n",
    "def ask(query: str, k: int = 3, remember: bool = True):\n",
    "    if not pdf_chunks:\n",
    "        print(\"No content indexed.\")\n",
    "        return\n",
    "    hits = retrieve(query, pdf_chunks, idf, k=k)\n",
    "    if not hits:\n",
    "        print(\"Sorry, I found nothing relevant.\")\n",
    "        return\n",
    "    result = summarize(query, hits)\n",
    "    if isinstance(result, str):\n",
    "        print(result); return\n",
    "    answer, sources = result\n",
    "    print(\"\\nAnswer:\\n\" + textwrap.fill(answer, width=100))\n",
    "    print(\"\\nSources:\")\n",
    "    for s in sources:\n",
    "        print(\" -\", s)\n",
    "    if remember:\n",
    "        append_memory(query, answer, sources)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
